{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict NYC Taxi Fares using ANN\n",
    "\n",
    "The goal is to estimate the cost of a New York City cab ride from several inputs.The inspiration behind this code along is a recent <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>Kaggle competition</a>.\n",
    "\n",
    "### STEPS:\n",
    "1. Read the data  : only a portion from the 55 million dataset is used (120,000 records from April 11 to April 24, 2010.)\n",
    "2. Features engineering :\n",
    " - Calculate distance\n",
    " - Derive useful data and time statistics\n",
    "3.  Deal with categorical data \n",
    " - Embedding\n",
    "4. Use of TabularModel class to work with both continuous and categorical data\n",
    " - Create a TabularModel class\n",
    " - Add in loss function and optimizer\n",
    " - Train/test split the data\n",
    " - Train the model\n",
    " - Evaluate on test data\n",
    " - Predict on brand new data\n",
    " \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a data frame\n",
    "df= pd.read_csv(\"../Data/NYCTaxiFares.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean         10.040326\n",
       "std           7.500134\n",
       "min           2.500000\n",
       "25%           5.700000\n",
       "50%           7.700000\n",
       "75%          11.300000\n",
       "max          49.900000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descrptive statistics on the fare amount\n",
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the average fare is \\\\$10.Minimum amount for a ride being \\\\$2.50 and maximum being \\\\$49.90 with a median of \\\\$7.70. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the dataframe to do feature engineering\n",
    "df1 = df.copy()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance caluclation\n",
    "Our goal is to predict the fares for a taxi ride in New York city. ususally it depends upon the distance. Here we have the longitudes and latitudes of the pickup and dropoff destinations. But these values look quite similar. To calculate the distance we will take the help of the <a href='https://en.wikipedia.org/wiki/Haversine_formula'>haversine formula</a> which calculates the distance on a sphere between two sets of GPS coordinates.<br>\n",
    "Here we assign latitude values with $\\varphi$ (phi) and longitude with $\\lambda$ (lambda).\n",
    "\n",
    "The distance formula works out to\n",
    "\n",
    "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{split} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2 in radians}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2 in radians}\\end{split}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the haversine formula in a function\n",
    "def haversine(df,long1,lat1,long2,lat2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in the dataframe df\n",
    "    \"\"\"\n",
    "    # r = radius of earth in kms\n",
    "    r = 6371\n",
    "    \n",
    "    # convert the longitude and latitude in radians\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    lambda1 = np.radians(df[long1])\n",
    "    lambda2 = np. radians(df[long2])\n",
    "    \n",
    "    a = np.square(np.sin((phi2-phi1)/2))\n",
    "    b = np.cos(phi1)* np.cos(phi2)* np.square((np.sin(lambda2-lambda1)/2))\n",
    "    c = np.sqrt(a+b)\n",
    "    d = 2*r* np.arcsin(c)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_kms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "   distance_kms  \n",
       "0      2.126312  \n",
       "1      1.392307  \n",
       "2      3.326763  \n",
       "3      1.864129  \n",
       "4      7.231319  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering the distance in Kms\n",
    "df1['distance_kms'] = haversine(df1,'pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering the day and time\n",
    "\n",
    "The time can also be an important predictor of the fare amount as it might vary on the weedays and peak hours. To evaluate this , we have to first convert it into a date time variable from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      "pickup_datetime      120000 non-null object\n",
      "fare_amount          120000 non-null float64\n",
      "fare_class           120000 non-null int64\n",
      "pickup_longitude     120000 non-null float64\n",
      "pickup_latitude      120000 non-null float64\n",
      "dropoff_longitude    120000 non-null float64\n",
      "dropoff_latitude     120000 non-null float64\n",
      "passenger_count      120000 non-null int64\n",
      "distance_kms         120000 non-null float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# The datetime columns is string \n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_kms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56+00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53+00:00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03+00:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01+00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "   distance_kms  \n",
       "0      2.126312  \n",
       "1      1.392307  \n",
       "2      3.326763  \n",
       "3      1.864129  \n",
       "4      7.231319  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['pickup_datetime'] = pd.to_datetime(df1['pickup_datetime'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      "pickup_datetime      120000 non-null datetime64[ns, UTC]\n",
      "fare_amount          120000 non-null float64\n",
      "fare_class           120000 non-null int64\n",
      "pickup_longitude     120000 non-null float64\n",
      "pickup_latitude      120000 non-null float64\n",
      "dropoff_longitude    120000 non-null float64\n",
      "dropoff_latitude     120000 non-null float64\n",
      "passenger_count      120000 non-null int64\n",
      "distance_kms         120000 non-null float64\n",
      "dtypes: datetime64[ns, UTC](1), float64(6), int64(2)\n",
      "memory usage: 8.2 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the pickup_datetime is in data time format. It is represented in UTC format. As New York is in Eastern Time Zone, so we have to convert to ETD by substracting 3 more hours. Also, there is daylight savings between April 11 to 24th, 2010, so we will add one more hour to convert to ETD zone. \n",
    "\n",
    "We will also extract the day of travel and if that is during AM or PM  to evaluate the impact on the fare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_kms</th>\n",
       "      <th>EDT_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56+00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53+00:00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03+00:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01+00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231319</td>\n",
       "      <td>2010-04-16 22:19:01+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "   distance_kms                  EDT_time  \n",
       "0      2.126312 2010-04-19 04:17:56+00:00  \n",
       "1      1.392307 2010-04-17 11:43:53+00:00  \n",
       "2      3.326763 2010-04-17 07:23:26+00:00  \n",
       "3      1.864129 2010-04-11 17:25:03+00:00  \n",
       "4      7.231319 2010-04-16 22:19:01+00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['EDT_time'] = df1['pickup_datetime']-pd.Timedelta(hours =4)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['day']=df1['EDT_time'].dt.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['hour'] = df1['EDT_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_kms</th>\n",
       "      <th>EDT_time</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>AMorPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56+00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56+00:00</td>\n",
       "      <td>Mon</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53+00:00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53+00:00</td>\n",
       "      <td>Sat</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26+00:00</td>\n",
       "      <td>Sat</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03+00:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03+00:00</td>\n",
       "      <td>Sun</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01+00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231319</td>\n",
       "      <td>2010-04-16 22:19:01+00:00</td>\n",
       "      <td>Fri</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "   distance_kms                  EDT_time  day  hour AMorPM  \n",
       "0      2.126312 2010-04-19 04:17:56+00:00  Mon     4     am  \n",
       "1      1.392307 2010-04-17 11:43:53+00:00  Sat    11     am  \n",
       "2      3.326763 2010-04-17 07:23:26+00:00  Sat     7     am  \n",
       "3      1.864129 2010-04-11 17:25:03+00:00  Sun    17     pm  \n",
       "4      7.231319 2010-04-16 22:19:01+00:00  Fri    22     pm  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['AMorPM'] = np.where(df1['hour']<12,'am','pm')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate categorical from continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['day','hour','AMorPM']\n",
    "cont_cols = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', \n",
    "             'dropoff_latitude','passenger_count', 'distance_kms']\n",
    "y_col = ['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categirify : converting the  columns into categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_cols:\n",
    "    df1[cat] = df1[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      datetime64[ns, UTC]\n",
       "fare_amount                      float64\n",
       "fare_class                         int64\n",
       "pickup_longitude                 float64\n",
       "pickup_latitude                  float64\n",
       "dropoff_longitude                float64\n",
       "dropoff_latitude                 float64\n",
       "passenger_count                    int64\n",
       "distance_kms                     float64\n",
       "EDT_time             datetime64[ns, UTC]\n",
       "day                             category\n",
       "hour                            category\n",
       "AMorPM                          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last three columns are now converted to categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: hour, dtype: category\n",
       "Categories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['hour'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         2\n",
       "2         2\n",
       "3         3\n",
       "4         0\n",
       "5         4\n",
       "6         0\n",
       "7         4\n",
       "8         5\n",
       "9         0\n",
       "10        4\n",
       "11        4\n",
       "12        0\n",
       "13        2\n",
       "14        6\n",
       "15        5\n",
       "16        4\n",
       "17        4\n",
       "18        6\n",
       "19        5\n",
       "20        5\n",
       "21        1\n",
       "22        5\n",
       "23        5\n",
       "24        6\n",
       "25        2\n",
       "26        3\n",
       "27        4\n",
       "28        0\n",
       "29        5\n",
       "         ..\n",
       "119970    3\n",
       "119971    4\n",
       "119972    0\n",
       "119973    2\n",
       "119974    2\n",
       "119975    5\n",
       "119976    5\n",
       "119977    5\n",
       "119978    3\n",
       "119979    6\n",
       "119980    6\n",
       "119981    4\n",
       "119982    6\n",
       "119983    6\n",
       "119984    0\n",
       "119985    1\n",
       "119986    0\n",
       "119987    1\n",
       "119988    3\n",
       "119989    2\n",
       "119990    3\n",
       "119991    1\n",
       "119992    0\n",
       "119993    1\n",
       "119994    3\n",
       "119995    3\n",
       "119996    0\n",
       "119997    3\n",
       "119998    5\n",
       "119999    2\n",
       "Length: 120000, dtype: int8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['day'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'pm'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['AMorPM'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So,we have hour divided in 24 , day in 7 and AMorPM in 2 categories. All these have been neumerically coded as well.\n",
    "Next we convert these categories to numpy arrays so that in future we can use neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkday = df1['day'].cat.codes.values\n",
    "hr = df1['hour'].cat.codes.values\n",
    "ampm = df1['AMorPM'].cat.codes.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11,  7, ..., 14,  4, 12], dtype=int8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check one of the variable\n",
    "hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  0],\n",
       "       [ 2, 11,  0],\n",
       "       [ 2,  7,  0],\n",
       "       [ 3, 17,  1],\n",
       "       [ 0, 22,  1]], dtype=int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack these \n",
    "cats=np.stack([wkday,hr,ampm],axis =1)\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the three categorical variables are represented as a numpy array with each column representing each variable - hour, day and am/pm value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of doing it is using list comprehension\n",
    "# cats = np.stack([df[col].cat.codes.values for col in cat_cols],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  0],\n",
       "        [ 2, 11,  0],\n",
       "        [ 2,  7,  0],\n",
       "        [ 3, 17,  1],\n",
       "        [ 0, 22,  1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert category array to tensor\n",
    "cats = torch.tensor(cats,dtype = torch.int64)\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of category tensor\n",
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-73.992365  ,  40.730521  , -73.975499  ,  40.744746  ,\n",
       "          1.        ,   2.12631158],\n",
       "       [-73.990078  ,  40.740558  , -73.974232  ,  40.744114  ,\n",
       "          1.        ,   1.39230685],\n",
       "       [-73.994149  ,  40.751118  , -73.960064  ,  40.766235  ,\n",
       "          2.        ,   3.32676333],\n",
       "       [-73.990485  ,  40.756422  , -73.971205  ,  40.748192  ,\n",
       "          1.        ,   1.86412923],\n",
       "       [-73.990976  ,  40.734202  , -73.905956  ,  40.743115  ,\n",
       "          1.        ,   7.23131908]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert continuos list to a numpy array to tensor\n",
    "conts = np.stack([df1[col].values for col in cont_cols],axis =1)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert continuos array to tensor\n",
    "conts = torch.tensor(conts, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the continuos tensor\n",
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5000],\n",
       "        [ 6.9000],\n",
       "        [10.1000],\n",
       "        [ 8.9000],\n",
       "        [19.7000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert label to tensor\n",
    "y = torch.tensor(df[y_col].values,dtype = torch.float).reshape(-1,1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the label tensor\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Embedding layer comes with PyTorch. It create a lookup table of fixed dictionary and size. We want to one hot encode the categories. \n",
    "\n",
    "### Set an embedding size\n",
    "The rule of thumb for determining the embedding size is to divide the number of unique entries in each column by 2, but not to exceed 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 24, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of how many categories we have in each column\n",
    "cat_szs = [len(df1[col].cat.categories) for col in cat_cols] \n",
    "cat_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 4), (24, 12), (2, 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set embedding sizes for the columns by dividing the number of unique entries in each column by 2, but not to exceed 50.\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs] # two forwards slashes because we want int output as it will be thse shape of array\n",
    "emb_szs # we get a list of tupules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,emb_szs,n_cont, out_sz, layers, p=0.5):\n",
    "        \n",
    "        # emb_szs - tupules - each categorical variable size is paired with an embedding size\n",
    "        # n_cont - number of continuous features\n",
    "        # Out_sz - output size = 1 as this is a regression problem\n",
    "        # layers - A list of number of neurons in each layer - can take any value for each layer and makes the network flexible\n",
    "        # p = probality for droupout layer defaulted  to 0.5\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #Create a list of the embedding layers \n",
    "        #Categorical data will be filtered through these Embeddings in the forward section.\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni,nf) for ni,nf in emb_szs]) \n",
    "        \n",
    "        #Set up a dropout function for the embeddings with torch.nn.Dropout() The default p-value=0.5\n",
    "        # randomly turns off p percent of neurons  to avoid overfitting\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        \n",
    "        #Set up a normalization function for the continuous variables with torch.nn.BatchNorm1d() \n",
    "        # to make sure all the data is within same manitude range\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        #Set up a sequence of neural network layers where each level includes a Linear function,\n",
    "        # an activation function (we'll use ReLU), a normalization step, and a dropout layer. \n",
    "        # We'll combine the list of layers with torch.nn.Sequential()\n",
    "        \n",
    "        \n",
    "        layerlist = [] # list to store layers\n",
    "        n_emb = sum([nf for ni, nf in emb_szs]) # number of total embeddings\n",
    "        n_in = n_emb + n_cont # total number of in features\n",
    "        \n",
    "        # setup the neural network layers\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) # A linear function layer with n_in as input feature and i as output feature\n",
    "            layerlist.append(nn.ReLU(inplace = True)) # Activation function \n",
    "            layerlist.append(nn.BatchNorm1d(i))# add the normalization process\n",
    "            layerlist.append(nn.Dropout(p)) #drop based on probality p\n",
    "            n_in =i\n",
    "            \n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz)) # output layer\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist) # combine all the layers together\n",
    "            \n",
    "    \n",
    "    def forward(self,x_cat,x_cont):\n",
    "        \n",
    "        # Define the forward method by passing :\n",
    "        # x_cat = categorical features\n",
    "        # x_cont = continuous features. \n",
    "        \n",
    "        # Preprocess the embeddings and normalize the continuous variables \n",
    "        # before passing them through the layers.\n",
    "\n",
    "        embeddings =[] # A placeholder list for embeddings\n",
    "        \n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i])) # create the embedding list by adding values\n",
    "       \n",
    "        x = torch.cat(embeddings, 1) # x is the output and concatenating it across the different categories\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        \n",
    "        # Use torch.cat() to combine multiple tensors into one.\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(7, 4)\n",
       "    (1): Embedding(24, 12)\n",
       "    (2): Embedding(2, 1)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=250, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=250, out_features=150, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4)\n",
       "    (8): Linear(in_features=150, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and Evaluate the model class by specifying the manual_seed\n",
    "torch.manual_seed(33)\n",
    "# we need to define the different variables required to passed into the class \n",
    "# n_cont - number of continuous features = no. of columns in the  continuos tensor - cont\n",
    "# Out_sz - output size = 1 as this is a regression problem\n",
    "# layers - A list of number of neurons in each layer - we have made a NN of two hidden layers with 200 and 150  neurons respectively\n",
    "# p = probality for droupout layer defaulted  to 0.5 - we have set here 0.4\n",
    "model = TabularModel(emb_szs, n_cont = conts.shape[1],out_sz= 1, layers = [250,150], p =0.4 )\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have intantiated the model by providing the required inputs. This results in a model with \n",
    "- embeds - a list of the embedding layers \n",
    "- emb_drop - dropdout value is set to 0.4\n",
    "- bn_cont - batch normalization is applied to the continous tensor\n",
    "- layers - Three hidden layers have been created and put together by sequential - \n",
    "           - In first hidden layer, no. of neurons input is 23(4+12+1+6) and no. of neurons going out is 200 (the                   value we provided)\n",
    "           - In second hidden layer, in_features=200, out_features=100\n",
    "           - In the third hidden layer , in_features=100, out_features=50\n",
    "           - Final output layer has in_features=50, out_features=1\n",
    "In every unit of every layer , these steps are performed:\n",
    "- A linear transformation is applied to the incoming data\n",
    "- the rectified linear unit function is applied element-wise and inplace\n",
    "- then Batch Normalization is applied over the output feature to increase the stability of a neural network.  This normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.\n",
    "- finally, randomly some of the elements of the input tensor with probability p using samples from a Bernoulli distribution are zeroed during training. Each channel will be zeroed out independently on every forward call.This has proven to be an effective technique for regularization and preventing the co-adaptation of neurons. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add loss function and opimizer\n",
    "\n",
    "PyTorch does not offer a built-in RMSE Loss function, so, we'll simply apply the torch.sqrt() function to the output of MSELoss during training.\n",
    "\n",
    "We will use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # we'll convert this to RMSE later\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  0],\n",
       "        [ 2, 11,  0],\n",
       "        [ 2,  7,  0],\n",
       "        [ 3, 17,  1],\n",
       "        [ 0, 22,  1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.59131908\n",
      "epoch:  26  loss: 11.19176865\n",
      "epoch:  51  loss: 10.05479717\n",
      "epoch:  76  loss: 9.24247169\n",
      "epoch: 101  loss: 8.29934978\n",
      "epoch: 126  loss: 7.03030157\n",
      "epoch: 151  loss: 5.48410463\n",
      "epoch: 176  loss: 4.07823896\n",
      "epoch: 201  loss: 3.49155474\n",
      "epoch: 226  loss: 3.40820932\n",
      "epoch: 251  loss: 3.36421084\n",
      "epoch: 276  loss: 3.33104229\n",
      "epoch: 301  loss: 3.30691695\n",
      "epoch: 326  loss: 3.25294924\n",
      "epoch: 351  loss: 3.25117254\n",
      "epoch: 376  loss: 3.23143816\n",
      "epoch: 401  loss: 3.22345281\n",
      "epoch: 426  loss: 3.21656156\n",
      "epoch: 451  loss: 3.19693732\n",
      "epoch: 476  loss: 3.19142056\n",
      "epoch: 500  loss: 3.16560078\n",
      "\n",
      "Duration: 44 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 500\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {(time.time() - start_time)/60:.0f} minutes') # print the time elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE loss')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs),losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model\n",
    "Here we want to run the entire test set through the model, and compare it to the known labels.\n",
    "For this step we don't want to update weights and biases, so we set torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.12279606\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val = model (cat_test,con_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDICTED   ACTUAL     DIFF\n",
      " 1.   3.2200   2.9000   0.3200\n",
      " 2.  21.0911   5.7000  15.3911\n",
      " 3.   5.5878   7.7000   2.1122\n",
      " 4.  11.9447  12.5000   0.5553\n",
      " 5.   4.2048   4.1000   0.1048\n",
      " 6.   6.3432   5.3000   1.0432\n",
      " 7.   4.6100   3.7000   0.9100\n",
      " 8.  18.3221  14.5000   3.8221\n",
      " 9.   4.1190   5.7000   1.5810\n",
      "10.  14.3831  10.1000   4.2831\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(10):\n",
    "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
