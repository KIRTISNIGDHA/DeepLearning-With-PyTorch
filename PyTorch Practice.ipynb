{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting array to tensor- method 1 \n",
    "x =torch .from_numpy(a) # creates alink between the numpy and the tensor, if you modify the cntent of numpy array then tensor also modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2\n",
    "torch.as_tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar2d = np.arange(0.0,12.0).reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.],\n",
       "       [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = torch.from_numpy(ar2d)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method 3\n",
    "arr = np.arange(1,10)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = torch.tensor(arr)\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying original array to see the effect on tensor\n",
    "X1 = torch.from_numpy(arr) # method 1\n",
    "X2 =torch.as_tensor(arr) #method 2\n",
    "X3 = torch.tensor(arr) #method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0] =0 # modfiy the first element of orginal array\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the other arrays\n",
    "X1 # modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 # modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 # not modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor converts into floats- shorthand for FloatTensor\n",
    "X4 = torch.Tensor(arr)\n",
    "X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3556e-19, 1.3563e-19],\n",
       "        [4.6114e+24, 6.4600e+19]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to initialize tensor\n",
    "torch.empty(2,2) # allocates a block of memory to later usuage for tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create a tensor of zeros of acertain dimension and data type\n",
    "torch.zeros(4,2,dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2,  4],\n",
       "        [ 6,  8, 10],\n",
       "        [12, 14, 16]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range start, end, step size\n",
    "torch.arange(0,18,2).reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.7273, 1.4545, 2.1818],\n",
       "        [2.9091, 3.6364, 4.3636, 5.0909],\n",
       "        [5.8182, 6.5455, 7.2727, 8.0000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linearly spcaed points\n",
    "torch.linspace(0,8,12).reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change data type\n",
    "X4.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert float to int\n",
    "X5 = X4.type(torch.int32)\n",
    "X5.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6578, 0.6982, 0.0120],\n",
       "        [0.3352, 0.6978, 0.9415],\n",
       "        [0.3417, 0.8797, 0.7043],\n",
       "        [0.3772, 0.0669, 0.6653]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random samples of tensor\n",
    "torch.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0100,  0.6359,  0.7163],\n",
       "        [-0.9146,  0.8751, -1.6288],\n",
       "        [-0.3421, -0.7345,  0.3887],\n",
       "        [-0.4969, -0.6519,  1.2023]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal distribution - mean = 0, std =1\n",
    "torch.randn(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 5, 3, 3, 4],\n",
       "        [9, 9, 3, 8, 2],\n",
       "        [1, 0, 7, 7, 2],\n",
       "        [2, 5, 6, 5, 6],\n",
       "        [8, 8, 5, 2, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random ints between a range, high is exclusive\n",
    "torch.randint(low=0,high=10,size=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.zeros(2,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5042, 0.8077, 0.2942, 0.7162, 0.2425],\n",
       "        [0.0183, 0.4715, 0.4804, 0.8408, 0.2989]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# produces tensor of similar shape of x\n",
    "torch.rand_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7215, -2.2367,  0.6815,  0.4720, -0.7795],\n",
       "        [ 0.1171,  0.5575,  0.0050, -1.1097, -1.8734]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 6., 0., 2., 2.],\n",
       "        [2., 0., 8., 7., 9.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the size first and then low and high values\n",
    "torch.randint_like(x,low=0, high=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829],\n",
       "        [0.9593, 0.3904, 0.6009]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility if you want same random values\n",
    "torch.manual_seed(42)# it should be in the same cell with the rand to get the exact same output\n",
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor operrations\n",
    "x= torch.arange(6).reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing for a column\n",
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slicing the column\n",
    "x[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,5) # just viewed in a particular shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to cahnge the tensor in place, ressign\n",
    "x= x.reshape(2,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z= torch.arange(10).view(2,5)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After reassigning uisng view , the new tensor is linked to the orginal one and any modification in original will afect the new one\n",
    "y = torch.arange(12)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.view(4,3)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 99999,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "           10,    11])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change element in y \n",
    "y[1]= 99999\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 99999,     2],\n",
       "        [    3,     4,     5],\n",
       "        [    6,     7,     8],\n",
       "        [    9,    10,    11]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check z\n",
    "z # it is alos modified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 99999,     2],\n",
       "        [    3,     4,     5],\n",
       "        [    6,     7,     8],\n",
       "        [    9,    10,    11]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = y.reshape(4,3)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 99999,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "         8888,    11])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify y\n",
    "y[10] = 8888\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 99999,     2],\n",
       "        [    3,     4,     5],\n",
       "        [    6,     7,     8],\n",
       "        [    9,  8888,    11]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r # r is also modified, this is important for neural networking study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 99999,     2,     3,     4,     5],\n",
       "        [    6,     7,     8,     9,  8888,    11]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer what the other dimension should be \n",
    "g = y.view(2,-1)\n",
    "g # it automatically inferred that the other dimensin should be 6 if the row is given to be 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 99999,     2,     3],\n",
       "        [    4,     5,     6,     7],\n",
       "        [    8,     9,  8888,    11]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = y.view(-1,4)\n",
    "h # similar ineference for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic arithmatics with tensors\n",
    "a = torch.tensor ([1.,2.,3.])\n",
    "b = torch.tensor ([4.,5.,6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b # elementwise addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the tensor in place by placing a unerscore \n",
    "a.add_(b) # a= a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orginal value of a is now changed\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 35., 54.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mul_(a) # b= b*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product\n",
    "c =a.dot(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor ([[1.,2.,3.],[6.,7.,8.]])\n",
    "b = torch.tensor ([[4.,5.],[3.,6.],[9.,10.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 37.,  47.],\n",
       "        [117., 152.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplications no or rows of tensor 1 must match with number of column of tensor b\n",
    "torch.mm(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 37.,  47.],\n",
       "        [117., 152.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b # anaother way to do matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elucidian norm\n",
    "x =torch.tensor([2.,3.,4.,5.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.6974)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of elements in the tensor \n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing len on a 2d array will give number of rows\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numel gives the number of elements\n",
    "a.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch gradients - Autogradients\n",
    "x = torch.tensor(2.0,requires_grad =True) # requires_grad keeps track the computational history, can turn it off also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2*x**4+x**3+3*x**2 + 5*x +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(63., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagation in one step \n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(93.)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 6.],\n",
       "        [7., 8., 9.]], requires_grad=True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backpropagation on multi layer \n",
    "# layer 1 = I/P is x, a 2x3 tensor\n",
    "x = torch.tensor([[4.,5,6],[7,8,9]], requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14., 17., 20.],\n",
       "        [23., 26., 29.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 2 is y \n",
    "y = 3*x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 392.,  578.,  800.],\n",
       "        [1058., 1352., 1682.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 3 is z\n",
    "z = 2 * y**2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(977., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 4 is o/p labelled as o = mean of z\n",
    "o = z.mean()\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28.0000, 34.0000, 40.0000],\n",
       "        [46.0000, 52.0000, 58.0000]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backpropagation of o wrt x\n",
    "o.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn # A lot of neural network functions come from torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.],\n",
       "        [11.],\n",
       "        [12.],\n",
       "        [13.],\n",
       "        [14.],\n",
       "        [15.],\n",
       "        [16.],\n",
       "        [17.],\n",
       "        [18.],\n",
       "        [19.],\n",
       "        [20.],\n",
       "        [21.],\n",
       "        [22.],\n",
       "        [23.],\n",
       "        [24.],\n",
       "        [25.],\n",
       "        [26.],\n",
       "        [27.],\n",
       "        [28.],\n",
       "        [29.],\n",
       "        [30.],\n",
       "        [31.],\n",
       "        [32.],\n",
       "        [33.],\n",
       "        [34.],\n",
       "        [35.],\n",
       "        [36.],\n",
       "        [37.],\n",
       "        [38.],\n",
       "        [39.],\n",
       "        [40.],\n",
       "        [41.],\n",
       "        [42.],\n",
       "        [43.],\n",
       "        [44.],\n",
       "        [45.],\n",
       "        [46.],\n",
       "        [47.],\n",
       "        [48.],\n",
       "        [49.],\n",
       "        [50.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# craete a column matrix \n",
    "X = torch.linspace(1,50,50).reshape(-1,1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.],\n",
       "        [ 7.],\n",
       "        [ 2.],\n",
       "        [ 6.],\n",
       "        [ 2.],\n",
       "        [-4.],\n",
       "        [ 2.],\n",
       "        [-5.],\n",
       "        [ 4.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 1.],\n",
       "        [-8.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [-6.],\n",
       "        [ 0.],\n",
       "        [-7.],\n",
       "        [-8.],\n",
       "        [-3.],\n",
       "        [-1.],\n",
       "        [ 2.],\n",
       "        [-6.],\n",
       "        [-3.],\n",
       "        [ 3.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 1.],\n",
       "        [ 7.],\n",
       "        [ 6.],\n",
       "        [-1.],\n",
       "        [-6.],\n",
       "        [-5.],\n",
       "        [-3.],\n",
       "        [ 7.],\n",
       "        [ 0.],\n",
       "        [ 8.],\n",
       "        [-1.],\n",
       "        [-2.],\n",
       "        [ 2.],\n",
       "        [-8.],\n",
       "        [-1.],\n",
       "        [ 6.],\n",
       "        [-8.],\n",
       "        [-3.],\n",
       "        [-7.],\n",
       "        [-2.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random array of error values to add some noise\n",
    "torch.manual_seed(71)\n",
    "e = torch.randint(-8,9,(50,1),dtype =torch.float)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the y value\n",
    "y = 2*X +1 +e \n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9937ab8d68>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to plot we have to convert to numpy \n",
    "plt.scatter(X.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use PyTorch to get a linear fit to the data.\n",
    "\n",
    "Since we have not specified requires_grad , there is no memory of the relationship between y and X and hence it can not backtrack. so y.backward() won't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple linear model\n",
    "- A simple linear layer model which takes a simple input and gives a simple output.\n",
    "- It doesn't really refer to linear regression. Instead, it describes the type of neural network layer employed. \n",
    "- Linear layers are also called \"fully connected\" or \"dense\" layers. \n",
    "- Our model can have different types of layers like  linear layer , convolution layer etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1060]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9638], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# The nn.Linear preselcts randomly weight and bias values if not specified\n",
    "torch.manual_seed(59)\n",
    "\n",
    "model = nn.Linear(in_features=1, out_features=1) # here in features is X and out featyres is y\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have random weight and bias values and the model is now tarcking the gradient ( requires_grad = True). \n",
    "\n",
    "\n",
    "### Model Class: \n",
    "PyTorch lets us define models as object classes that can store multiple model layers. This will be helpful to create multiple layers with their own feed forward functions for the next layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear model class.\n",
    "\n",
    "class Model(nn.Module): # Define a class model which inherits from - torch.nn.Module - Base class for all neural network modules.\n",
    "    \n",
    "    def __init__(self, in_features, out_features): # instatiation method \n",
    "        \n",
    "        super().__init__() # instantiates the inherited class Module \n",
    "        self.linear = nn.Linear(in_features, out_features)# instantiate with a single linear layer (similar to what we did while craeting a simple linear model)\n",
    "        \n",
    "        \n",
    "    def forward(self,x): # the forward method\n",
    "        y_pred = self.linear(x) # incoming data X is linearly transformed and o/p is stored in y\n",
    "        return y_pred # return the y predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "Weight: 0.10597813129425049\n",
      "Bias:   0.9637961387634277\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model class using the previously set selected random values( by specifying the same manual_seed)\n",
    "\n",
    "torch.manual_seed(59)\n",
    "\n",
    "model = Model(1,1)\n",
    "\n",
    "print(model)\n",
    "print('Weight:', model.linear.weight.item())\n",
    "print('Bias:  ', model.linear.bias.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to what we got in the simple linear model so our class is functioning properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.weight \t 0.10597813129425049\n",
      "linear.bias \t 0.9637961387634277\n"
     ]
    }
   ],
   "source": [
    "# What are the parameters in the model \n",
    "for name, param in model.named_parameters(): # named_parameters comes from the torch.nn.Module class which we have inherited in the model class\n",
    "    print(name,'\\t', param.item()) # prints all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1758], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Now evalaute how the model takes a new value and predicts the y value using the weights and biases it has randomly determined\n",
    "x = torch.tensor([2.0])\n",
    "print(model.forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the predicted value if x = 2.0 by using the model's linear transformaion , weight *x + bias, we get y = 1.1758. \n",
    "\n",
    "Let's again use the values between x =0-50, how our model performs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight: 0.10597813, Initial bias: 0.96379614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9935011240>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# now let's evalaute how the model performs with a randowm weight and bias value the modle has\n",
    "\n",
    "w1,b1 = model.linear.weight.item(), model.linear.bias.item()\n",
    "print(f'Initial weight: {w1:.8f}, Initial bias: {b1:.8f}')\n",
    "\n",
    "# let's deine our y\n",
    "y1 = w1*X + b1\n",
    "\n",
    "# how does the model perform wrt to our real values\n",
    "plt.scatter(X.numpy(), y.numpy()) # real values of x and y \n",
    "plt.plot(X.numpy(),y1.numpy(),'r') # new predicted values using the random weights and biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not set loss function. so the model just randomly picked a weight and bias value and it didn't give a good prediction as can be seen from the red line. \n",
    "\n",
    "Let's define our loss function. we select the mean squared loss MSE loss usually labeled as criterion as this is based on which we will be evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function \n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set optimizer:\n",
    "stochastic gradient descent with a learning rate which tells how much the parameters needs to be adjusted. \n",
    "we select a starter learning rate. \n",
    "- if the model is converging slowly, choose a larger value.\n",
    "-  or if it's not converging may be the lr is too high and is overshooting the global minima. so,then reduce the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the Epoch - \n",
    "how many times the model will run and evalaute through the whole data set. Here we choose a larger epoch for a simple dataset to see where the model converges.\n",
    "\n",
    "Now, in our data we have prespecified y = 2X +1+e, where weight = 2 and bias = 1. Our model will try to predict the values somewhere closer to that by iterating over and over (epoch) evaluating with the optimizer by using the loss function. It wont be perfect in the prediction though because we have added random noise , e, to our data. \n",
    "\n",
    "We will also keep tarck of the variation in the loss function after each epoch and plot it to see if that loss decreases with time or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch\n",
    "epochs = 50\n",
    "# placeholder to track MSE losses\n",
    "losses =[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss = 3057.216796875, Weight = 0.10597813129425049, bias =0.9637961387634277 \n",
      "Epoch: 2, Loss = 1588.531005859375, Weight = 3.334900379180908, bias =1.0604636669158936 \n",
      "Epoch: 3, Loss = 830.3001098632812, Weight = 1.0148327350616455, bias =0.9922627806663513 \n",
      "Epoch: 4, Loss = 438.8524169921875, Weight = 2.6817996501922607, bias =1.0425218343734741 \n",
      "Epoch: 5, Loss = 236.7615203857422, Weight = 1.4840211868286133, bias =1.0076650381088257 \n",
      "Epoch: 6, Loss = 132.4291229248047, Weight = 2.3446059226989746, bias =1.0339646339416504 \n",
      "Epoch: 7, Loss = 78.56572723388672, Weight = 1.7262253761291504, bias =1.0163217782974243 \n",
      "Epoch: 8, Loss = 50.75775909423828, Weight = 2.170504093170166, bias =1.0302516222000122 \n",
      "Epoch: 9, Loss = 36.4012336730957, Weight = 1.8512457609176636, bias =1.0214954614639282 \n",
      "Epoch: 10, Loss = 28.989227294921875, Weight = 2.0806007385253906, bias =1.029038906097412 \n",
      "Epoch: 11, Loss = 25.162382125854492, Weight = 1.9157683849334717, bias =1.0248701572418213 \n",
      "Epoch: 12, Loss = 23.186473846435547, Weight = 2.034165620803833, bias =1.0291162729263306 \n",
      "Epoch: 13, Loss = 22.166128158569336, Weight = 1.9490584135055542, bias =1.027315616607666 \n",
      "Epoch: 14, Loss = 21.639110565185547, Weight = 2.010172128677368, bias =1.0298590660095215 \n",
      "Epoch: 15, Loss = 21.366771697998047, Weight = 1.9662237167358398, bias =1.0292805433273315 \n",
      "Epoch: 16, Loss = 21.22591781616211, Weight = 1.997764229774475, bias =1.030944585800171 \n",
      "Epoch: 17, Loss = 21.15294647216797, Weight = 1.9750648736953735, bias =1.0309966802597046 \n",
      "Epoch: 18, Loss = 21.11501121520996, Weight = 1.991337537765503, bias =1.032206416130066 \n",
      "Epoch: 19, Loss = 21.095176696777344, Weight = 1.9796085357666016, bias =1.0325838327407837 \n",
      "Epoch: 20, Loss = 21.084684371948242, Weight = 1.9879988431930542, bias =1.0335586071014404 \n",
      "Epoch: 21, Loss = 21.07901382446289, Weight = 1.981933355331421, bias =1.034103512763977 \n",
      "Epoch: 22, Loss = 21.075830459594727, Weight = 1.9862544536590576, bias =1.034956693649292 \n",
      "Epoch: 23, Loss = 21.073938369750977, Weight = 1.9831126928329468, bias =1.0355877876281738 \n",
      "Epoch: 24, Loss = 21.07269859313965, Weight = 1.9853330850601196, bias =1.0363779067993164 \n",
      "Epoch: 25, Loss = 21.071819305419922, Weight = 1.9837009906768799, bias =1.037053108215332 \n",
      "Epoch: 26, Loss = 21.07110595703125, Weight = 1.9848365783691406, bias =1.037810206413269 \n",
      "Epoch: 27, Loss = 21.070484161376953, Weight = 1.9839837551116943, bias =1.0385079383850098 \n",
      "Epoch: 28, Loss = 21.069913864135742, Weight = 1.9845597743988037, bias =1.039247751235962 \n",
      "Epoch: 29, Loss = 21.069366455078125, Weight = 1.9841090440750122, bias =1.0399566888809204 \n",
      "Epoch: 30, Loss = 21.068836212158203, Weight = 1.9843961000442505, bias =1.0406872034072876 \n",
      "Epoch: 31, Loss = 21.068307876586914, Weight = 1.984152913093567, bias =1.0414016246795654 \n",
      "Epoch: 32, Loss = 21.067781448364258, Weight = 1.9842908382415771, bias =1.042127013206482 \n",
      "Epoch: 33, Loss = 21.067262649536133, Weight = 1.9841549396514893, bias =1.0428439378738403 \n",
      "Epoch: 34, Loss = 21.066740036010742, Weight = 1.9842157363891602, bias =1.043566346168518 \n",
      "Epoch: 35, Loss = 21.06622314453125, Weight = 1.9841355085372925, bias =1.0442842245101929 \n",
      "Epoch: 36, Loss = 21.065706253051758, Weight = 1.9841564893722534, bias =1.0450047254562378 \n",
      "Epoch: 37, Loss = 21.065189361572266, Weight = 1.9841045141220093, bias =1.0457227230072021 \n",
      "Epoch: 38, Loss = 21.064668655395508, Weight = 1.9841052293777466, bias =1.046441912651062 \n",
      "Epoch: 39, Loss = 21.064157485961914, Weight = 1.9840680360794067, bias =1.0471596717834473 \n",
      "Epoch: 40, Loss = 21.06363868713379, Weight = 1.984058141708374, bias =1.0478779077529907 \n",
      "Epoch: 41, Loss = 21.06312370300293, Weight = 1.984028697013855, bias =1.0485951900482178 \n",
      "Epoch: 42, Loss = 21.062606811523438, Weight = 1.9840131998062134, bias =1.0493125915527344 \n",
      "Epoch: 43, Loss = 21.062095642089844, Weight = 1.98398756980896, bias =1.0500292778015137 \n",
      "Epoch: 44, Loss = 21.06157875061035, Weight = 1.9839695692062378, bias =1.0507458448410034 \n",
      "Epoch: 45, Loss = 21.06106948852539, Weight = 1.9839458465576172, bias =1.051461935043335 \n",
      "Epoch: 46, Loss = 21.06055450439453, Weight = 1.9839262962341309, bias =1.0521777868270874 \n",
      "Epoch: 47, Loss = 21.060041427612305, Weight = 1.9839037656784058, bias =1.0528931617736816 \n",
      "Epoch: 48, Loss = 21.059532165527344, Weight = 1.9838833808898926, bias =1.0536082983016968 \n",
      "Epoch: 49, Loss = 21.05901527404785, Weight = 1.9838614463806152, bias =1.0543230772018433 \n",
      "Epoch: 50, Loss = 21.058509826660156, Weight = 1.9838409423828125, bias =1.055037498474121 \n"
     ]
    }
   ],
   "source": [
    "# looping through the dataset for the epochs specified and evalauting the loss\n",
    "for i in range(epochs):\n",
    "    i +=1\n",
    "    \n",
    "    # predict the y \n",
    "    y_pred = model.forward(X)\n",
    "    \n",
    "    # Evaluate the loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # append to the loss list\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # print the epoch, loss and parameters to see how it varies with each iteration\n",
    "    print (f\"Epoch: {i}, Loss = {loss}, Weight = {model.linear.weight.item()}, bias ={model.linear.bias.item()} \")\n",
    "    \n",
    "    # resetting the gradients to prevent compunding, because it will accumulate with each iteration and backpropagation and affect computation\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "    # update the hyperparameters which here are the weights and biases\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in the first epoch we have a huge loss value because it randomly assigns weights and biases. However as we iterate and backprogation happens, the loss decreases with each eapoch till we have weight value around 2 and bias around 1 which ahs been achied by epoch 14. Ater that the loss values does not change much as teh weight and bias doesnot change a lot. The model has converged at that point.  We can see the same thing in the plot between loss and epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs),losses)\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the model to make predictions\n",
    "\n",
    "Now our model is ready and we can use it to make predictions. \n",
    "We need to provide the input and the parameters - weights and biases that we have got after training the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,50,50) # here we choose a similar input to evalaute the model's performance\n",
    "current_weight = model.linear.weight.item()\n",
    "current_bias = model.linear.bias.item()\n",
    "\n",
    "predicted_y = current_weight * x + current_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9935200780>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evalauting on the real values how well our model preicts\n",
    "plt.scatter(X.numpy(),y.numpy())\n",
    "plt.plot(x,predicted_y,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see the model gives a good prediction although it's not perfect because of the presence of the random noise we added to the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../Data/iris.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('target', axis =1).values # we just get the values \n",
    "label = df['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1 :Convert files to tensors after splitting using the scikit learn\n",
    "X_train, X_test,y_train,y_test = train_test_split(features, label, test_size =0.2, random_state= 33)\n",
    "# here the test and train sets are in arrays , we will convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train) # we want to create floating values\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train) # The targets are integers\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 2, 0, 1,\n",
       "        2, 2, 1, 1, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1,\n",
       "        2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 1, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 0, 2, 2, 2, 1, 2, 0, 1, 0, 0, 0, 2, 1, 2, 1, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y_train is a long vector. To convert it into columns we will reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "# we could have done it in one step as well. y_test = torch.LongTensor(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 : Using the builtin utility function\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch's builtin test train split feature\n",
    "iris = TensorDataset(torch.FloatTensor(features),torch.LongTensor(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now iris is a  tensor dataset\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.9000, 3.0000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.7000, 3.2000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([4.6000, 3.1000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.6000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([5.4000, 3.9000, 1.7000, 0.4000]), tensor(0))\n",
      "(tensor([4.6000, 3.4000, 1.4000, 0.3000]), tensor(0))\n",
      "(tensor([5.0000, 3.4000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([4.4000, 2.9000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.9000, 3.1000, 1.5000, 0.1000]), tensor(0))\n",
      "(tensor([5.4000, 3.7000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([4.8000, 3.4000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([4.8000, 3.0000, 1.4000, 0.1000]), tensor(0))\n",
      "(tensor([4.3000, 3.0000, 1.1000, 0.1000]), tensor(0))\n",
      "(tensor([5.8000, 4.0000, 1.2000, 0.2000]), tensor(0))\n",
      "(tensor([5.7000, 4.4000, 1.5000, 0.4000]), tensor(0))\n",
      "(tensor([5.4000, 3.9000, 1.3000, 0.4000]), tensor(0))\n",
      "(tensor([5.1000, 3.5000, 1.4000, 0.3000]), tensor(0))\n",
      "(tensor([5.7000, 3.8000, 1.7000, 0.3000]), tensor(0))\n",
      "(tensor([5.1000, 3.8000, 1.5000, 0.3000]), tensor(0))\n",
      "(tensor([5.4000, 3.4000, 1.7000, 0.2000]), tensor(0))\n",
      "(tensor([5.1000, 3.7000, 1.5000, 0.4000]), tensor(0))\n",
      "(tensor([4.6000, 3.6000, 1.0000, 0.2000]), tensor(0))\n",
      "(tensor([5.1000, 3.3000, 1.7000, 0.5000]), tensor(0))\n",
      "(tensor([4.8000, 3.4000, 1.9000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.0000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.4000, 1.6000, 0.4000]), tensor(0))\n",
      "(tensor([5.2000, 3.5000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([5.2000, 3.4000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.7000, 3.2000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([4.8000, 3.1000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([5.4000, 3.4000, 1.5000, 0.4000]), tensor(0))\n",
      "(tensor([5.2000, 4.1000, 1.5000, 0.1000]), tensor(0))\n",
      "(tensor([5.5000, 4.2000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.9000, 3.1000, 1.5000, 0.1000]), tensor(0))\n",
      "(tensor([5.0000, 3.2000, 1.2000, 0.2000]), tensor(0))\n",
      "(tensor([5.5000, 3.5000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([4.9000, 3.1000, 1.5000, 0.1000]), tensor(0))\n",
      "(tensor([4.4000, 3.0000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([5.1000, 3.4000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.5000, 1.3000, 0.3000]), tensor(0))\n",
      "(tensor([4.5000, 2.3000, 1.3000, 0.3000]), tensor(0))\n",
      "(tensor([4.4000, 3.2000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.5000, 1.6000, 0.6000]), tensor(0))\n",
      "(tensor([5.1000, 3.8000, 1.9000, 0.4000]), tensor(0))\n",
      "(tensor([4.8000, 3.0000, 1.4000, 0.3000]), tensor(0))\n",
      "(tensor([5.1000, 3.8000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([4.6000, 3.2000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([5.3000, 3.7000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.3000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([7.0000, 3.2000, 4.7000, 1.4000]), tensor(1))\n",
      "(tensor([6.4000, 3.2000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([6.9000, 3.1000, 4.9000, 1.5000]), tensor(1))\n",
      "(tensor([5.5000, 2.3000, 4.0000, 1.3000]), tensor(1))\n",
      "(tensor([6.5000, 2.8000, 4.6000, 1.5000]), tensor(1))\n",
      "(tensor([5.7000, 2.8000, 4.5000, 1.3000]), tensor(1))\n",
      "(tensor([6.3000, 3.3000, 4.7000, 1.6000]), tensor(1))\n",
      "(tensor([4.9000, 2.4000, 3.3000, 1.0000]), tensor(1))\n",
      "(tensor([6.6000, 2.9000, 4.6000, 1.3000]), tensor(1))\n",
      "(tensor([5.2000, 2.7000, 3.9000, 1.4000]), tensor(1))\n",
      "(tensor([5.0000, 2.0000, 3.5000, 1.0000]), tensor(1))\n",
      "(tensor([5.9000, 3.0000, 4.2000, 1.5000]), tensor(1))\n",
      "(tensor([6.0000, 2.2000, 4.0000, 1.0000]), tensor(1))\n",
      "(tensor([6.1000, 2.9000, 4.7000, 1.4000]), tensor(1))\n",
      "(tensor([5.6000, 2.9000, 3.6000, 1.3000]), tensor(1))\n",
      "(tensor([6.7000, 3.1000, 4.4000, 1.4000]), tensor(1))\n",
      "(tensor([5.6000, 3.0000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([5.8000, 2.7000, 4.1000, 1.0000]), tensor(1))\n",
      "(tensor([6.2000, 2.2000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([5.6000, 2.5000, 3.9000, 1.1000]), tensor(1))\n",
      "(tensor([5.9000, 3.2000, 4.8000, 1.8000]), tensor(1))\n",
      "(tensor([6.1000, 2.8000, 4.0000, 1.3000]), tensor(1))\n",
      "(tensor([6.3000, 2.5000, 4.9000, 1.5000]), tensor(1))\n",
      "(tensor([6.1000, 2.8000, 4.7000, 1.2000]), tensor(1))\n",
      "(tensor([6.4000, 2.9000, 4.3000, 1.3000]), tensor(1))\n",
      "(tensor([6.6000, 3.0000, 4.4000, 1.4000]), tensor(1))\n",
      "(tensor([6.8000, 2.8000, 4.8000, 1.4000]), tensor(1))\n",
      "(tensor([6.7000, 3.0000, 5.0000, 1.7000]), tensor(1))\n",
      "(tensor([6.0000, 2.9000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([5.7000, 2.6000, 3.5000, 1.0000]), tensor(1))\n",
      "(tensor([5.5000, 2.4000, 3.8000, 1.1000]), tensor(1))\n",
      "(tensor([5.5000, 2.4000, 3.7000, 1.0000]), tensor(1))\n",
      "(tensor([5.8000, 2.7000, 3.9000, 1.2000]), tensor(1))\n",
      "(tensor([6.0000, 2.7000, 5.1000, 1.6000]), tensor(1))\n",
      "(tensor([5.4000, 3.0000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([6.0000, 3.4000, 4.5000, 1.6000]), tensor(1))\n",
      "(tensor([6.7000, 3.1000, 4.7000, 1.5000]), tensor(1))\n",
      "(tensor([6.3000, 2.3000, 4.4000, 1.3000]), tensor(1))\n",
      "(tensor([5.6000, 3.0000, 4.1000, 1.3000]), tensor(1))\n",
      "(tensor([5.5000, 2.5000, 4.0000, 1.3000]), tensor(1))\n",
      "(tensor([5.5000, 2.6000, 4.4000, 1.2000]), tensor(1))\n",
      "(tensor([6.1000, 3.0000, 4.6000, 1.4000]), tensor(1))\n",
      "(tensor([5.8000, 2.6000, 4.0000, 1.2000]), tensor(1))\n",
      "(tensor([5.0000, 2.3000, 3.3000, 1.0000]), tensor(1))\n",
      "(tensor([5.6000, 2.7000, 4.2000, 1.3000]), tensor(1))\n",
      "(tensor([5.7000, 3.0000, 4.2000, 1.2000]), tensor(1))\n",
      "(tensor([5.7000, 2.9000, 4.2000, 1.3000]), tensor(1))\n",
      "(tensor([6.2000, 2.9000, 4.3000, 1.3000]), tensor(1))\n",
      "(tensor([5.1000, 2.5000, 3.0000, 1.1000]), tensor(1))\n",
      "(tensor([5.7000, 2.8000, 4.1000, 1.3000]), tensor(1))\n",
      "(tensor([6.3000, 3.3000, 6.0000, 2.5000]), tensor(2))\n",
      "(tensor([5.8000, 2.7000, 5.1000, 1.9000]), tensor(2))\n",
      "(tensor([7.1000, 3.0000, 5.9000, 2.1000]), tensor(2))\n",
      "(tensor([6.3000, 2.9000, 5.6000, 1.8000]), tensor(2))\n",
      "(tensor([6.5000, 3.0000, 5.8000, 2.2000]), tensor(2))\n",
      "(tensor([7.6000, 3.0000, 6.6000, 2.1000]), tensor(2))\n",
      "(tensor([4.9000, 2.5000, 4.5000, 1.7000]), tensor(2))\n",
      "(tensor([7.3000, 2.9000, 6.3000, 1.8000]), tensor(2))\n",
      "(tensor([6.7000, 2.5000, 5.8000, 1.8000]), tensor(2))\n",
      "(tensor([7.2000, 3.6000, 6.1000, 2.5000]), tensor(2))\n",
      "(tensor([6.5000, 3.2000, 5.1000, 2.0000]), tensor(2))\n",
      "(tensor([6.4000, 2.7000, 5.3000, 1.9000]), tensor(2))\n",
      "(tensor([6.8000, 3.0000, 5.5000, 2.1000]), tensor(2))\n",
      "(tensor([5.7000, 2.5000, 5.0000, 2.0000]), tensor(2))\n",
      "(tensor([5.8000, 2.8000, 5.1000, 2.4000]), tensor(2))\n",
      "(tensor([6.4000, 3.2000, 5.3000, 2.3000]), tensor(2))\n",
      "(tensor([6.5000, 3.0000, 5.5000, 1.8000]), tensor(2))\n",
      "(tensor([7.7000, 3.8000, 6.7000, 2.2000]), tensor(2))\n",
      "(tensor([7.7000, 2.6000, 6.9000, 2.3000]), tensor(2))\n",
      "(tensor([6.0000, 2.2000, 5.0000, 1.5000]), tensor(2))\n",
      "(tensor([6.9000, 3.2000, 5.7000, 2.3000]), tensor(2))\n",
      "(tensor([5.6000, 2.8000, 4.9000, 2.0000]), tensor(2))\n",
      "(tensor([7.7000, 2.8000, 6.7000, 2.0000]), tensor(2))\n",
      "(tensor([6.3000, 2.7000, 4.9000, 1.8000]), tensor(2))\n",
      "(tensor([6.7000, 3.3000, 5.7000, 2.1000]), tensor(2))\n",
      "(tensor([7.2000, 3.2000, 6.0000, 1.8000]), tensor(2))\n",
      "(tensor([6.2000, 2.8000, 4.8000, 1.8000]), tensor(2))\n",
      "(tensor([6.1000, 3.0000, 4.9000, 1.8000]), tensor(2))\n",
      "(tensor([6.4000, 2.8000, 5.6000, 2.1000]), tensor(2))\n",
      "(tensor([7.2000, 3.0000, 5.8000, 1.6000]), tensor(2))\n",
      "(tensor([7.4000, 2.8000, 6.1000, 1.9000]), tensor(2))\n",
      "(tensor([7.9000, 3.8000, 6.4000, 2.0000]), tensor(2))\n",
      "(tensor([6.4000, 2.8000, 5.6000, 2.2000]), tensor(2))\n",
      "(tensor([6.3000, 2.8000, 5.1000, 1.5000]), tensor(2))\n",
      "(tensor([6.1000, 2.6000, 5.6000, 1.4000]), tensor(2))\n",
      "(tensor([7.7000, 3.0000, 6.1000, 2.3000]), tensor(2))\n",
      "(tensor([6.3000, 3.4000, 5.6000, 2.4000]), tensor(2))\n",
      "(tensor([6.4000, 3.1000, 5.5000, 1.8000]), tensor(2))\n",
      "(tensor([6.0000, 3.0000, 4.8000, 1.8000]), tensor(2))\n",
      "(tensor([6.9000, 3.1000, 5.4000, 2.1000]), tensor(2))\n",
      "(tensor([6.7000, 3.1000, 5.6000, 2.4000]), tensor(2))\n",
      "(tensor([6.9000, 3.1000, 5.1000, 2.3000]), tensor(2))\n",
      "(tensor([5.8000, 2.7000, 5.1000, 1.9000]), tensor(2))\n",
      "(tensor([6.8000, 3.2000, 5.9000, 2.3000]), tensor(2))\n",
      "(tensor([6.7000, 3.3000, 5.7000, 2.5000]), tensor(2))\n",
      "(tensor([6.7000, 3.0000, 5.2000, 2.3000]), tensor(2))\n",
      "(tensor([6.3000, 2.5000, 5.0000, 1.9000]), tensor(2))\n",
      "(tensor([6.5000, 3.0000, 5.2000, 2.0000]), tensor(2))\n",
      "(tensor([6.2000, 3.4000, 5.4000, 2.3000]), tensor(2))\n",
      "(tensor([5.9000, 3.0000, 5.1000, 1.8000]), tensor(2))\n"
     ]
    }
   ],
   "source": [
    "# the features and labels are now float and intigers and we can ieterate \n",
    "for i in iris:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader:\n",
    "using dataloader we can shuffle and produce batches of data. Good for large dataset where you can feed one batch at a time in one epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_loader = DataLoader(iris, batch_size = 50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
      "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000]]), tensor([1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 1, 0, 0, 1, 2, 1, 2, 1, 2,\n",
      "        0, 0, 1, 2, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 2, 1, 2, 2, 0, 1, 0, 1, 2, 0,\n",
      "        0, 0])]\n",
      "1 [tensor([[6.2000, 2.2000, 4.5000, 1.5000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
      "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000]]), tensor([1, 2, 0, 1, 1, 0, 2, 1, 0, 0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 1, 1, 1, 2,\n",
      "        0, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 1, 0, 1, 0, 2, 0, 1, 1, 2, 2,\n",
      "        1, 1])]\n",
      "2 [tensor([[5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
      "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
      "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
      "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000]]), tensor([0, 2, 2, 0, 2, 0, 1, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 1,\n",
      "        1, 0, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 2, 1,\n",
      "        0, 2])]\n"
     ]
    }
   ],
   "source": [
    "# let's check those batches\n",
    "for i_batch, sample_batch in enumerate(iris_loader):\n",
    "    print(i_batch,sample_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have split the data into a size of 50 and the total length of dataset is 150, we have three batches and randomly shuffled. By varying the batch size we can again change the numbe rof batch sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we just want to iterate through the batches, we can do it in this way\n",
    "for batch in iris_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
